{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import random\n",
    "import unidecode\n",
    "import time\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sn\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "from torchtext.utils import download_from_url, extract_archive\n",
    "from torch.autograd import Variable\n",
    "from torchtext import legacy\n",
    "from torch import autograd\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torchtext\n",
    "\n",
    "import gensim\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import HungarianStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import nltk\n",
    "\n",
    "import hu_core_ud_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_files(path):\n",
    "    return glob.glob(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(filename):\n",
    "    with open(filename) as json_file:\n",
    "        data = json.load(json_file)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Az adathalmaz letöltése"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_tar = download_from_url('https://drive.google.com/uc?id=1k7GfVRqrHFK00ABkit0oGQo62fCakMSZ', root='.data/')\n",
    "extracted_files = extract_archive(dataset_tar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adatok olvasása\n",
    "Adatok beolvasása JSON fájlként, majd egy nagy pandas-os DataFrame-mé alakítása."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file: .data/gyakori_szamitastechnika\n",
      "Reading file: .data/gyakori_egeszseg\n",
      "Reading file: .data/gyakori_egeszseg_20000\n",
      "Reading file: .data/gyakori_allatok_14000\n",
      "Reading file: .data/gyakori_szorakozas_30000\n"
     ]
    }
   ],
   "source": [
    "json_data = []\n",
    "\n",
    "for file in find_files('.data/gyakori_*'):\n",
    "    print(\"Reading file:\", file)\n",
    "    json_data.append(read_json(file))\n",
    "    \n",
    "data_frame = pd.DataFrame()\n",
    "\n",
    "for data in json_data:\n",
    "    frames  = [data_frame, pd.DataFrame(data)]\n",
    "    data_frame = pd.concat(frames).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bepillantás a kérdésekbe\n",
    "Csak hogy tudjuk pontosan mivel is állunk szemben. Minden kérdéshez tartozik a kérdés rövid, illetve hosszú verziója, egy válasz, amit a felhasználók a leghasznosabbnak találtak. Ezeken kívül kategóriák és kulcsszavak is vannak a kérdéshez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valasz</th>\n",
       "      <th>kategoriak</th>\n",
       "      <th>hosszu_kerdes</th>\n",
       "      <th>rovid_kerdes</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Várak régen is voltak. Ha mindhárom tornyot le...</td>\n",
       "      <td>[Számítástechnika, Internet]</td>\n",
       "      <td>Miért lett ilyen sz@r a honfoglaló? Régen tök ...</td>\n",
       "      <td>Miért lett ilyen sz@r a honfoglaló?</td>\n",
       "      <td>[Honfoglaló, vár]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ahogy írták, az stdio az a C-s függvénykönyvtá...</td>\n",
       "      <td>[Számítástechnika, Programozás]</td>\n",
       "      <td>C++-ban melyiket érdemesebb használni? Stdio v...</td>\n",
       "      <td>C++-ban melyiket érdemesebb használni? Stdio v...</td>\n",
       "      <td>[C++, iostream, konzol, Windows, Visual Studio]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              valasz  \\\n",
       "0  Várak régen is voltak. Ha mindhárom tornyot le...   \n",
       "1  Ahogy írták, az stdio az a C-s függvénykönyvtá...   \n",
       "\n",
       "                        kategoriak  \\\n",
       "0     [Számítástechnika, Internet]   \n",
       "1  [Számítástechnika, Programozás]   \n",
       "\n",
       "                                       hosszu_kerdes  \\\n",
       "0  Miért lett ilyen sz@r a honfoglaló? Régen tök ...   \n",
       "1  C++-ban melyiket érdemesebb használni? Stdio v...   \n",
       "\n",
       "                                        rovid_kerdes  \\\n",
       "0                Miért lett ilyen sz@r a honfoglaló?   \n",
       "1  C++-ban melyiket érdemesebb használni? Stdio v...   \n",
       "\n",
       "                                          keywords  \n",
       "0                                [Honfoglaló, vár]  \n",
       "1  [C++, iostream, konzol, Windows, Visual Studio]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Túl kicsi kategóriák szűrése\n",
    "Ha egy kategóriához túl kevés kérdés tartozik, akkor nem érdemes a továbbiakban foglalkozni vele. A túl kicsi kategóriák szűrése következik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = data_frame['kategoriak'].apply(lambda x: x[0]).unique().tolist()\n",
    "\n",
    "minimum_questions_for_each_category = 3000\n",
    "\n",
    "for target in target_names:\n",
    "    target_size = data_frame[data_frame['kategoriak'].apply(lambda x : x[0]) == target].shape[0]\n",
    "    if target_size < minimum_questions_for_each_category:\n",
    "        data_frame = data_frame[data_frame['kategoriak'].apply(lambda x : x[0]) != target]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Túl rövid kérdések szűrése\n",
    "A túl rövid kérdések nem túl hasznosak. Az adathalmazban előfordul pár 2 szóból álló HOSSZÚ kérdés. Vegyük például a következő kérdéseket: `Militaryra appalosa?`, `Ivabradine vélemények?`. Ezek a kérdések nem meghatározóak a témájukra nézve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum_words_per_question = 5\n",
    "data_frame = data_frame[data_frame['hosszu_kerdes'].apply(lambda x: len(x.split())) >= minimum_words_per_question]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Főkategóriák\" kigyűjtése\n",
    "Az egyes főkategóriák neveinek kigyűjtése, majd az egyes nevekhez egy azonosító szám rendelése."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_names(idx, data_frame):\n",
    "    target_names = data_frame['kategoriak'].apply(lambda x: x[idx]).unique().tolist()\n",
    "    target_dict =  {value: key for key, value in enumerate(target_names)}\n",
    "    \n",
    "    return target_names, target_dict, len(target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Számítástechnika', 'Egészség', 'Állatok', 'Szórakozás']\n",
      "{'Számítástechnika': 0, 'Egészség': 1, 'Állatok': 2, 'Szórakozás': 3}\n",
      "Kategóriák száma:  4\n"
     ]
    }
   ],
   "source": [
    "target_names, target_dict, num_of_categories = get_target_names(0, data_frame)\n",
    "\n",
    "print(target_names)\n",
    "print(target_dict)\n",
    "print(\"Kategóriák száma: \", num_of_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tanító adathalmaz előállítása\n",
    "A tanító adathalmazban minden egyes főkategóriából ugyanannyi kérdésnek kell szerepelnie (így fair). Itt pontosan ez történik `questions_from_each_category` darab kérdés kerül a tanító adathalmazba minden kategóriából, majd az eredményül kapott tömb véletlenszerűen összekeveredik.\n",
    "\n",
    "#### Shuffle together\n",
    "A shuffle_together függvény két listát véletlenszerűen kever össze, úgy, hogy az a keverés előtt az egyes listákban azonos indexen szereplő értékek a keverés után is azonos indexen lesznek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_together(list1, list2):\n",
    "    zipped = list(zip(list1, list2))\n",
    "    random.shuffle(zipped)\n",
    "    list1, list2 = zip(*zipped)\n",
    "    \n",
    "    return (list(list1), list(list2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Least questions in category\n",
    "Ez a találó nevű függvény azt akarja kiszámolni, hogy a legkevesebb kérdéssel rendelkező kategóriában mennyi kérdés van. Ezt azért számolom ki, hogy a tanító és tesztelő adathalmazokba ugyanannyi kérdés kerülhessen minden kategóriába.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_questions_in_ctg(idx, target_names, data_frame):\n",
    "    min_amount = float('inf')\n",
    "\n",
    "    for target_name in target_names:\n",
    "        amount = len(data_frame[data_frame[\"kategoriak\"].apply(lambda x : x[idx]) == target_name]['kategoriak'])\n",
    "        min_amount = min(amount, min_amount)\n",
    "    return min_amount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_datasets(train_ratio, questions_size, ctg_idx, data_frame, num_of_categories, target_names, target_dict):\n",
    "    \n",
    "    train_each_ctg = int(train_ratio * questions_size)\n",
    "    train_size = train_each_ctg * num_of_categories\n",
    "    train_questions = []\n",
    "    train_target = []\n",
    "    \n",
    "    test_each_ctg = int((1.0 - train_ratio) * questions_size)\n",
    "    test_size = test_each_ctg * num_of_categories\n",
    "    test_questions = []\n",
    "    test_target = []\n",
    "    \n",
    "    for target_name in target_names:\n",
    "        train_questions += data_frame[data_frame[\"kategoriak\"].apply(lambda x: x[ctg_idx]) == target_name][0:train_each_ctg][\"hosszu_kerdes\"].to_list()\n",
    "        train_target += [target_dict[target_name]] * train_each_ctg    \n",
    "    \n",
    "        test_questions += data_frame[data_frame[\"kategoriak\"].apply(lambda x: x[ctg_idx]) == target_name][train_each_ctg:train_each_ctg + test_each_ctg][\"hosszu_kerdes\"].to_list()\n",
    "        test_target += [target_dict[target_name]] * test_each_ctg\n",
    "    \n",
    "    train_questions, train_target = shuffle_together(train_questions, train_target)\n",
    "    test_questions, test_target = shuffle_together(test_questions, test_target)\n",
    "    \n",
    "    return train_each_ctg, train_size, train_questions, train_target,\\\n",
    "        test_each_ctg, test_size, test_questions, test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.80\n",
    "test_ratio = 1.0 - train_ratio\n",
    "\n",
    "min_amount = least_questions_in_ctg(0, target_names, data_frame)\n",
    "train_each_ctg, train_size, train_questions, train_target, \\\n",
    "    test_each_ctg, test_size, test_questions, test_target = \\\n",
    "        split_datasets(train_ratio, min_amount, 0, data_frame, num_of_categories, target_names, target_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def unicode_to_ascii(data):\n",
    "    return unidecode.unidecode(re.sub(r\"[,.;@#?!&$]+\\ *\", \" \", data).lower()).split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab(questions):\n",
    "    vocab = set()\n",
    "    \n",
    "    for idx, question in enumerate(questions):\n",
    "        words = unicode_to_ascii(question)\n",
    "\n",
    "        for idx in range(len(words)):\n",
    "            vocab.add(words[idx])\n",
    "\n",
    "    vocab_size = len(vocab)\n",
    "\n",
    "    index_to_word = {}\n",
    "\n",
    "    for idx, word in enumerate(vocab):\n",
    "        index_to_word[word] = idx\n",
    "        \n",
    "    return vocab, vocab_size, index_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vocab, vocab_size, index_to_word = get_vocab(train_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(text, target, i, batch_size, input_size, index_to):\n",
    "\n",
    "    batches = []\n",
    "    results = []\n",
    "    \n",
    "    texts = text[i * batch_size : (i + 1) * batch_size]\n",
    "    categories = target[i * batch_size : (i + 1) * batch_size]\n",
    "\n",
    "    for text in texts:\n",
    "        layer = np.zeros(input_size, dtype=float)\n",
    "        words = unicode_to_ascii(text)\n",
    "        \n",
    "        for word in words:\n",
    "            if word in index_to:\n",
    "                layer[index_to[word]] += 1\n",
    "            \n",
    "        batches.append(layer)\n",
    "        \n",
    "    for category in categories:\n",
    "        results.append(category)\n",
    "     \n",
    "    return np.array(batches), np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "num_epochs = 2\n",
    "batch_size = 200\n",
    "\n",
    "hidden_size = 100\n",
    "input_size = vocab_size\n",
    "num_classes = len(target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BOWClassification(nn.Module):\n",
    "     def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(BOWClassification, self).__init__()\n",
    "        self.layer_1 = nn.Linear(input_size, hidden_size, bias=True)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layer_2 = nn.Linear(hidden_size, hidden_size, bias=True)\n",
    "        self.output_layer = nn.Linear(hidden_size, num_classes, bias=True)\n",
    " \n",
    "     def forward(self, x):\n",
    "        out = self.layer_1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.layer_2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.output_layer(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_net(vocab_size, hidden_size, num_classes, learning_rate, num_epochs, train_questions, train_target, batch_size, index_to_word):\n",
    "    net = BOWClassification(vocab_size, hidden_size, num_classes)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()  \n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)  \n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        if epoch:\n",
    "            print()\n",
    "        print(\"Epoch %d/%d: \" % (epoch + 1, num_epochs))\n",
    "        total_batch = len(train_questions) // batch_size\n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = get_batch(train_questions, train_target, i, batch_size, vocab_size, index_to_word)\n",
    "            questions = Variable(torch.FloatTensor(batch_x))\n",
    "            themes = Variable(torch.LongTensor(batch_y))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(questions)\n",
    "            loss = criterion(outputs, themes)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            print(\"\\r[%d/%d] %.2f%%\" % (i + 1, total_batch, (i + 1)/ total_batch * 100), end=\"\")\n",
    "    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = get_net(vocab_size, hidden_size, num_classes, learning_rate, num_epochs, train_questions, train_target, batch_size, index_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_net(net, test_q, test_t, batch_s, vocab_s, index2word):\n",
    "    total_batch = len(test_q) // batch_s\n",
    "\n",
    "    total_pred = []\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        test_batch_x, test_batch_y = get_batch(test_q, test_t, i, batch_s, vocab_s, index2word)\n",
    "        print(\"\\rTesting... [%d/%d] %.2f%%\" % (i + 1, total_batch, (i + 1)/ total_batch * 100), end=\"\")\n",
    "\n",
    "        questions = Variable(torch.FloatTensor(test_batch_x))\n",
    "        themes = Variable(torch.FloatTensor(test_batch_y))\n",
    "\n",
    "        outputs = net(questions)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_pred += predicted.tolist()\n",
    "        \n",
    "    return total_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_predicted = test_net(net, test_questions, test_target, batch_size, vocab_size, index_to_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tesztelés eredménye\n",
    "\n",
    "### Confusion matrix\n",
    "Tévesztési mátrix magyarul. A mátrix `i` sorában, `j` oszlopában szereplő érték (ebben az esetben) azt jelenti, hogy a mondat a `i` kategóriájú, de a háló `j` kategóriát ismert fel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(test_target[0:len(total_predicted)], total_predicted)\n",
    "cm_df = pd.DataFrame(cm, index=target_names, columns=target_names)\n",
    "\n",
    "heatmap = sn.heatmap(cm_df, annot=True, cmap='Reds', fmt='g', annot_kws={\"size\": 15}, cbar=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification report\n",
    "#### Accuracy\n",
    "A accuracy érték jelentése: a kérdések mekkora részét sikerült helyesen osztályozni.\n",
    "#### Precision\n",
    "A Szórakozás kategóriához tartozó precision érték azt jelenti, hogy az összes Szórakozás kategóriába sorolt kérdés közül mekkora arányban vannak a ténylegesen Szórakozás kategóriájú kérdések.\n",
    "#### Recall\n",
    "A recall érték a precision értékhez eléggé hasonló. Az összes ténylegesen Szórakozás kategóriájú kérdés mekkora részét sorolta Szórakozás kategóriába az osztályozó."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_report = classification_report(test_target[0:len(total_predicted)], total_predicted, target_names=target_names)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alkategória osztályozás\n",
    "A főkategória osztályozáshoz hasonló módszerrel próbálkozva. A 4 főkategóriát most elkülönítjük egymástól, 1 tanító adathalamzban csak 1 főkategóriához tartozó kérdések lesznek. Ennek megfelelően az eddig látott dolgokból 4 fog kelleni (háló, tévesztési mátrix, tanító-, tesztelő halmaz stb.)\n",
    "\n",
    "#### Get target names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names_sub = {}\n",
    "target_dict_sub = {}\n",
    "num_of_ctg_sub = {}\n",
    "\n",
    "filtered_df = {}\n",
    "\n",
    "for t in target_names:\n",
    "    filtered_df[t] = data_frame[data_frame['kategoriak'].apply(lambda x: x[0]) == t]\n",
    "    filtered_df[t] = filtered_df[t][filtered_df[t]['kategoriak'].apply(lambda x: x[1]) != 'Egyéb kérdések']\n",
    "    target_names_sub[t], target_dict_sub[t], num_of_ctg_sub[t] = get_target_names(1, filtered_df[t])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.8\n",
    "\n",
    "min_amount_sub = {}\n",
    "\n",
    "train_each_sub = {}\n",
    "train_questions_sub = {}\n",
    "train_size_sub = {}\n",
    "train_target_sub = {}\n",
    "\n",
    "test_each_sub = {}\n",
    "test_questions_sub = {}\n",
    "test_size_sub = {}\n",
    "test_target_sub = {}\n",
    "\n",
    "for t in target_names:\n",
    "    min_amount_sub[t] = least_questions_in_ctg(1, target_names_sub[t], filtered_df[t])\n",
    "    \n",
    "    train_each_sub[t], train_size_sub[t], train_questions_sub[t], train_target_sub[t], \\\n",
    "        test_each_sub[t], test_size_sub[t], test_questions_sub[t], test_target_sub[t] = \\\n",
    "            split_datasets(train_ratio, min_amount_sub[t], 1, filtered_df[t], num_of_ctg_sub[t], target_names_sub[t], target_dict_sub[t])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_sub = {}\n",
    "vocab_size_sub = {}\n",
    "index_to_word_sub = {}\n",
    "\n",
    "for t in target_names:\n",
    "    vocab_sub[t], vocab_size_sub[t], index_to_word_sub[t] = get_vocab(train_questions_sub[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.005\n",
    "num_epochs = 2\n",
    "batch_size = 75\n",
    "\n",
    "hidden_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "net_sub = {}\n",
    "\n",
    "for t in target_names:\n",
    "    print(t)\n",
    "    net_sub[t] = get_net(vocab_size_sub[t], hidden_size, num_of_ctg_sub[t], learning_rate, num_epochs, train_questions_sub[t], train_target_sub[t], batch_size, index_to_word_sub[t])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_pred_sub = {}\n",
    "\n",
    "for t in target_names:\n",
    "    print(t)\n",
    "    total_pred_sub[t] = test_net(net_sub[t], test_questions_sub[t], test_target_sub[t], batch_size, vocab_size_sub[t], index_to_word_sub[t])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in target_names:\n",
    "    cm = confusion_matrix(test_target_sub[t][0:len(total_pred_sub[t])], total_pred_sub[t])\n",
    "    cm_df = pd.DataFrame(cm, index=target_names_sub[t], columns=target_names_sub[t])\n",
    "\n",
    "    plt.figure(figsize = (10,8))\n",
    "    heatmap = sn.heatmap(cm_df, annot=True, cmap='Reds', fmt='g', annot_kws={\"size\": 15}, cbar=False)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in target_names:\n",
    "    class_report = classification_report(test_target_sub[t][0:len(total_pred_sub[t])], total_pred_sub[t], target_names=target_names_sub[t])\n",
    "    print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding\n",
    "Get hungarian glove file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/nlp/glove-hu.200k.200d.txt'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_from_url('https://drive.google.com/uc?id=19k2AACA90Qv1BeUBz8H6trCT4QTJ8OjW', root='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-29-4a803d046eea>:4: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
      "  _ = glove2word2vec(glove_file, gensim_file)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "glove_file = \"glove-hu.200k.200d.txt\"\n",
    "gensim_file = \"glove-hu.200k.200d_gensim\"\n",
    "\n",
    "_ = glove2word2vec(glove_file, gensim_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = gensim.models.KeyedVectors.load_word2vec_format(gensim_file, binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "/usr/local/lib/python3.8/dist-packages/spacy/util.py:275: UserWarning: [W031] Model 'hu_core_ud_lg' (0.3.1) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.5). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "stemmer = HungarianStemmer()\n",
    "q = train_questions[0]\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('hungarian'))\n",
    "\n",
    "# tokenizálás\n",
    "tokenized_sentence = tokenizer.tokenize(q)\n",
    "\n",
    "# stop word szűrés\n",
    "filtered_sentence = [w for w in tokenized_sentence if not w in stop_words]\n",
    "\n",
    "# lemmatizáció\n",
    "lemmatizer = hu_core_ud_lg.load()\n",
    "\n",
    "lemmatizer.remove_pipe('parser')\n",
    "lemmatizer.remove_pipe('ner')\n",
    "lemmatizer.add_pipe(lemmatizer.create_pipe('sentencizer'))\n",
    "\n",
    "doc = lemmatizer(\" \".join(filtered_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eredeti kérdés:\n",
      "Tudnátok írni pár hobbit? Mostanában sokat unatkozok és ki kéne valami jó elfoglaltságot.. Köszönöm :)\n",
      "\n",
      "Tokenizálás utáni kérdés:\n",
      "Tudnátok írni pár hobbit Mostanában sokat unatkozok és ki kéne valami jó elfoglaltságot Köszönöm \n",
      "\n",
      "Stop Word szűrés utáni kérdés:\n",
      "Tudnátok írni pár hobbit Mostanában unatkozok kéne elfoglaltságot Köszönöm \n",
      "\n",
      "Lemmatizáció utáni kérdés:\n",
      "tudnát ír pár hobbi mostanában unatkoz kell elfoglaltság köszön \n",
      "\n",
      "Stemming utáni kérdés:\n",
      "tudnát írn pár hobb mostan sok unatkoz és ki kén valam jó elfoglaltság köszönö "
     ]
    }
   ],
   "source": [
    "print(\"Eredeti kérdés:\")\n",
    "print(q)\n",
    "\n",
    "print(\"\\nTokenizálás utáni kérdés:\")\n",
    "for w in tokenized_sentence:\n",
    "    print(w, end=\" \")\n",
    "\n",
    "print(\"\\n\\nStop Word szűrés utáni kérdés:\")\n",
    "for w in filtered_sentence:\n",
    "    print(w, end=\" \")\n",
    "\n",
    "print(\"\\n\\nLemmatizáció utáni kérdés:\")\n",
    "for w in doc:\n",
    "    print(w.lemma_.lower(), end=\" \")\n",
    "    \n",
    "print(\"\\n\\nStemming utáni kérdés:\")\n",
    "for w in tokenized_sentence:\n",
    "    print(stemmer.stem(w), end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_question(question):\n",
    "    doc = lemmatizer(question)\n",
    "    lemmatized = []\n",
    "    \n",
    "    for w in doc:\n",
    "        lemmatized.append(w.lemma_.lower())\n",
    "    return \" \".join(lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_question(question):\n",
    "    stemmed = []\n",
    "    \n",
    "    for w in question.split():\n",
    "        stemmed.append(stemmer.stem(w))\n",
    "    return \" \".join(stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(questions):\n",
    "    lemmatized_list = []\n",
    "    stemmed_list = []\n",
    "    lemmatized_filtered_list = []\n",
    "    stemmed_filtered_list = []\n",
    "    \n",
    "    start_time = int(time.time() * 1000)\n",
    "    \n",
    "    for idx, q in enumerate(questions):\n",
    "        tokenized = tokenizer.tokenize(q)\n",
    "        tokenized_q = \" \".join(tokenized)\n",
    "        filtered = [w for w in tokenized if not w in stop_words]\n",
    "\n",
    "        filtered_q = \" \".join(filtered)\n",
    "\n",
    "        lemmatized_list.append(lemmatize_question(tokenized_q))\n",
    "        stemmed_list.append(stem_question(tokenized_q))\n",
    "        \n",
    "        lemmatized_filtered_list.append(lemmatize_question(filtered_q))\n",
    "        stemmed_filtered_list.append(stem_question(filtered_q))\n",
    "\n",
    "        if idx % 100 == 0:\n",
    "            print(\"\\r%8d / %8d\" % (idx, len(questions)), end=\"\")\n",
    "\n",
    "    print()\n",
    "    end_time = int(time.time() * 1000)\n",
    "    print(\"Creating datasets took: %f seconds\" % ((end_time - start_time) / 1000.0))\n",
    "\n",
    "    return lemmatized_list, stemmed_list, lemmatized_filtered_list, stemmed_filtered_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_train = []\n",
    "lemmatized_test = []\n",
    "\n",
    "stemmed_train = []\n",
    "stemmed_test = []\n",
    "\n",
    "lemmatized_filtered_train = []\n",
    "lemmatized_filtered_test = []\n",
    "\n",
    "stemmed_filtered_train = []\n",
    "stemmed_filtered_test = []\n",
    "\n",
    "lemmatized_train, stemmed_train, lemmatized_filtered_train, stemmed_filtered_train = create_datasets(train_questions)\n",
    "print(\"Train datasets are ready\")\n",
    "lemmatized_test, stemmed_test, lemmatized_filtered_test, stemmed_filtered_test = create_datasets(test_questions)\n",
    "print(\"Test datasets are ready\")\n",
    "    \n",
    "lemma_trdf = pd.DataFrame(list(zip(train_target, lemmatized_train)), columns =['Target', 'Question']) \n",
    "lemma_tedf = pd.DataFrame(list(zip(test_target, lemmatized_test)), columns =['Target', 'Question'])\n",
    "\n",
    "stem_trdf = pd.DataFrame(list(zip(train_target, stemmed_train)), columns =['Target', 'Question']) \n",
    "stem_tedf = pd.DataFrame(list(zip(test_target, stemmed_test)), columns =['Target', 'Question'])\n",
    "\n",
    "lemmaf_trdf = pd.DataFrame(list(zip(train_target, lemmatized_filtered_train)), columns =['Target', 'Question']) \n",
    "lemmaf_tedf = pd.DataFrame(list(zip(test_target, lemmatized_filtered_test)), columns =['Target', 'Question'])\n",
    "\n",
    "stemf_trdf = pd.DataFrame(list(zip(train_target, stemmed_filtered_train)), columns =['Target', 'Question']) \n",
    "stemf_tedf = pd.DataFrame(list(zip(test_target, stemmed_filtered_test)), columns =['Target', 'Question'])\n",
    "\n",
    "lemma_trdf.to_csv(\".csv/lemma_trdf.csv\", index=False)\n",
    "lemma_tedf.to_csv(\".csv/lemma_tedf.csv\", index=False)\n",
    "\n",
    "stem_trdf.to_csv(\".csv/stem_trdf.csv\", index=False)\n",
    "stem_tedf.to_csv(\".csv/stem_tedf.csv\", index=False)\n",
    "\n",
    "lemmaf_trdf.to_csv(\".csv/lemmaf_trdf.csv\", index=False)\n",
    "lemmaf_tedf.to_csv(\".csv/lemmaf_tedf.csv\", index=False)\n",
    "\n",
    "stemf_trdf.to_csv(\".csv/stemf_trdf.csv\", index=False)\n",
    "stemf_tedf.to_csv(\".csv/stemf_tedf.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_tar = download_from_url('https://drive.google.com/uc?id=1LQkdBq9KW0wqgT9NG0k0VpCGqAtCGFkB', root='.csv/')\n",
    "extracted_files = extract_archive(dataset_tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION = legacy.data.Field(tokenize = 'spacy', tokenizer_language = 'hu_core_ud_lg')\n",
    "TARGET = legacy.data.LabelField(dtype = torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [('Target', TARGET),('Question', QUESTION)]\n",
    "\n",
    "train, test = legacy.data.TabularDataset.splits(\n",
    "                                        path = '.csv',\n",
    "                                        train = 'lemma_trdf.csv',\n",
    "                                        test = 'lemma_tedf.csv',\n",
    "                                        format = 'csv',\n",
    "                                        fields = fields,\n",
    "                                        skip_header = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = train.split(random_state = random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = torchtext.vocab.Vectors('glove-hu.200k.200d_gensim', cache = '.')\n",
    "\n",
    "QUESTION.build_vocab(train, vectors = vec)  \n",
    "TARGET.build_vocab(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = legacy.data.BucketIterator.splits((train, valid, test), batch_size = BATCH_SIZE,\n",
    "                                                                           sort_key = lambda x: len(x.Question),\n",
    "                                                                           sort_within_batch = False,\n",
    "                                                                           device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
    "        \n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.embedding.weight.data.copy_(QUESTION.vocab.vectors)\n",
    "        self.embedding.weight.requires_grad=True\n",
    "        \n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        \n",
    "    def forward(self, text):\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "\n",
    "        output, hidden = self.lstm(embedded)\n",
    "\n",
    "        y = self.fc(output[-1])\n",
    "        \n",
    "        log_probs = F.log_softmax(y.squeeze(0))\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(QUESTION.vocab)\n",
    "EMBEDDING_DIM = 200\n",
    "HIDDEN_DIM = 100\n",
    "OUTPUT_DIM = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMClassifier(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_accuracy(preds, y):\n",
    "    rounded_preds = preds.argmax(1)\n",
    "    correct = (rounded_preds == y).float()\n",
    "\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "                \n",
    "        predictions = model(batch.Question)\n",
    "\n",
    "        loss = criterion(predictions, batch.Target)\n",
    "        \n",
    "        acc = class_accuracy(predictions, batch.Target)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    total_predicted = []\n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "            predictions = model(batch.Question)\n",
    "            loss = criterion(predictions, batch.Target)\n",
    "            \n",
    "            acc = class_accuracy(predictions, batch.Target)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "            _, predicted = torch.max(predictions.data, 1)\n",
    "            total_predicted += predicted.tolist()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), total_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-42-17170b95c49c>:24: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  log_probs = F.log_softmax(y.squeeze(0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 21s\n",
      "\tTrain Loss: 1.385 | Train Acc: 25.12%\n",
      "\t Val. Loss: 1.311 |  Val. Acc: 37.98%\n",
      "Epoch: 02 | Epoch Time: 0m 21s\n",
      "\tTrain Loss: 1.309 | Train Acc: 30.72%\n",
      "\t Val. Loss: 1.426 |  Val. Acc: 28.62%\n",
      "Epoch: 03 | Epoch Time: 0m 22s\n",
      "\tTrain Loss: 1.325 | Train Acc: 29.44%\n",
      "\t Val. Loss: 0.864 |  Val. Acc: 60.47%\n",
      "Epoch: 04 | Epoch Time: 0m 22s\n",
      "\tTrain Loss: 0.777 | Train Acc: 60.75%\n",
      "\t Val. Loss: 0.629 |  Val. Acc: 77.06%\n",
      "Epoch: 05 | Epoch Time: 0m 22s\n",
      "\tTrain Loss: 0.254 | Train Acc: 92.45%\n",
      "\t Val. Loss: 0.406 |  Val. Acc: 88.54%\n",
      "Epoch: 06 | Epoch Time: 0m 22s\n",
      "\tTrain Loss: 0.151 | Train Acc: 95.86%\n",
      "\t Val. Loss: 0.347 |  Val. Acc: 90.38%\n",
      "Epoch: 07 | Epoch Time: 0m 22s\n",
      "\tTrain Loss: 0.062 | Train Acc: 98.36%\n",
      "\t Val. Loss: 0.333 |  Val. Acc: 90.27%\n",
      "Epoch: 08 | Epoch Time: 0m 21s\n",
      "\tTrain Loss: 0.035 | Train Acc: 99.17%\n",
      "\t Val. Loss: 0.299 |  Val. Acc: 90.74%\n",
      "Epoch: 09 | Epoch Time: 0m 21s\n",
      "\tTrain Loss: 0.022 | Train Acc: 99.52%\n",
      "\t Val. Loss: 0.292 |  Val. Acc: 91.16%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 30\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train_(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc, _ = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'LSTM.pt')\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('LSTM.pt'))\n",
    "\n",
    "test_loss, test_acc, total_predicted = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_target = []\n",
    "\n",
    "for batch in test_iterator:\n",
    "    test_target += batch.Target.tolist()\n",
    "\n",
    "cm = confusion_matrix(test_target, total_predicted)\n",
    "cm_df = pd.DataFrame(cm, index=target_names, columns=target_names)\n",
    "\n",
    "heatmap = sn.heatmap(cm_df, annot=True, cmap='Reds', fmt='g', annot_kws={\"size\": 15}, cbar=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_token_idx = tokenizer.cls_token_id\n",
    "eos_token_idx = tokenizer.sep_token_id\n",
    "pad_token_idx = tokenizer.pad_token_id\n",
    "unk_token_idx = tokenizer.unk_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_length = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_cut(sentence):\n",
    "    tokens = tokenizer.tokenize(sentence) \n",
    "    tokens = tokens[:max_input_length-2]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.legacy import data\n",
    "\n",
    "QUESTION = data.Field(batch_first = True,\n",
    "                        use_vocab = False,\n",
    "                        tokenize = tokenize_and_cut,\n",
    "                        preprocessing = tokenizer.convert_tokens_to_ids,\n",
    "                        init_token = init_token_idx,\n",
    "                        eos_token = eos_token_idx,\n",
    "                        pad_token = pad_token_idx,\n",
    "                        unk_token = unk_token_idx)\n",
    "TARGET = data.LabelField(dtype = torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [('Target', TARGET),('Question', QUESTION)]\n",
    "\n",
    "train_data, test_data = legacy.data.TabularDataset.splits(\n",
    "                                        path = '.csv',\n",
    "                                        train = 'lemma_trdf.csv',\n",
    "                                        test = 'lemma_tedf.csv',\n",
    "                                        format = 'csv',\n",
    "                                        fields = fields,\n",
    "                                        skip_header = True\n",
    ")\n",
    "\n",
    "train_data, valid_data = train_data.split(random_state = random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    sort_key = lambda x: len(x.Question),\n",
    "    sort_within_batch = False,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "bert = BertForSequenceClassification.from_pretrained('bert-base-multilingual-uncased', num_labels = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT(nn.Module):\n",
    "\n",
    "    def __init__(self, bert):\n",
    "        super(BERT, self).__init__()\n",
    "        self.encoder = bert\n",
    "\n",
    "    def forward(self, text, target):\n",
    "        loss, text_fea = self.encoder(text, labels=target)[:2]\n",
    "\n",
    "        return loss, text_fea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(save_path, model, valid_loss):\n",
    "\n",
    "    if save_path == None:\n",
    "        return\n",
    "    \n",
    "    state_dict = {'model_state_dict': model.state_dict(),\n",
    "                  'valid_loss': valid_loss}\n",
    "    \n",
    "    torch.save(state_dict, save_path)\n",
    "    print(f'Model saved to ==> {save_path}')\n",
    "\n",
    "\n",
    "def save_metrics(save_path, train_loss_list, valid_loss_list, global_steps_list):\n",
    "\n",
    "    if save_path == None:\n",
    "        return\n",
    "    \n",
    "    state_dict = {'train_loss_list': train_loss_list,\n",
    "                  'valid_loss_list': valid_loss_list,\n",
    "                  'global_steps_list': global_steps_list}\n",
    "    \n",
    "    torch.save(state_dict, save_path)\n",
    "    print(f'Model saved to ==> {save_path}')\n",
    "\n",
    "\n",
    "def load_metrics(load_path):\n",
    "\n",
    "    if load_path==None:\n",
    "        return\n",
    "    \n",
    "    state_dict = torch.load(load_path, map_location=device)\n",
    "    print(f'Model loaded from <== {load_path}')\n",
    "    \n",
    "    return state_dict['train_loss_list'], state_dict['valid_loss_list'], state_dict['global_steps_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3269 / 6539\n",
      "Epoch [1/8], Step [3269/52312], Train Loss: 0.1643, Valid Loss: 0.1968\n",
      "Model saved to ==> ./model.pt\n",
      "Model saved to ==> ./metrics.pt\n",
      "6538 / 6539\n",
      "Epoch [1/8], Step [6538/52312], Train Loss: 0.1599, Valid Loss: 0.1757\n",
      "Model saved to ==> ./model.pt\n",
      "Model saved to ==> ./metrics.pt\n",
      "3268 / 6539\n",
      "Epoch [2/8], Step [9807/52312], Train Loss: 0.1137, Valid Loss: 0.1955\n",
      "6537 / 6539\n",
      "Epoch [2/8], Step [13076/52312], Train Loss: 0.1212, Valid Loss: 0.2208\n",
      "3267 / 6539\n",
      "Epoch [3/8], Step [16345/52312], Train Loss: 0.0876, Valid Loss: 0.2005\n",
      "6536 / 6539\n",
      "Epoch [3/8], Step [19614/52312], Train Loss: 0.0956, Valid Loss: 0.2045\n",
      "3266 / 6539\n",
      "Epoch [4/8], Step [22883/52312], Train Loss: 0.0707, Valid Loss: 0.1859\n",
      "6535 / 6539\n",
      "Epoch [4/8], Step [26152/52312], Train Loss: 0.0760, Valid Loss: 0.2577\n",
      "3265 / 6539\n",
      "Epoch [5/8], Step [29421/52312], Train Loss: 0.0562, Valid Loss: 0.2159\n",
      "6534 / 6539\n",
      "Epoch [5/8], Step [32690/52312], Train Loss: 0.0624, Valid Loss: 0.2235\n",
      "3264 / 6539\n",
      "Epoch [6/8], Step [35959/52312], Train Loss: 0.0459, Valid Loss: 0.3190\n",
      "6533 / 6539\n",
      "Epoch [6/8], Step [39228/52312], Train Loss: 0.0546, Valid Loss: 0.2235\n",
      "3263 / 6539\n",
      "Epoch [7/8], Step [42497/52312], Train Loss: 0.0407, Valid Loss: 0.2692\n",
      "6532 / 6539\n",
      "Epoch [7/8], Step [45766/52312], Train Loss: 0.0470, Valid Loss: 0.2662\n",
      "3262 / 6539\n",
      "Epoch [8/8], Step [49035/52312], Train Loss: 0.0338, Valid Loss: 0.2915\n",
      "6531 / 6539"
     ]
    }
   ],
   "source": [
    "def train(model,\n",
    "          optimizer,\n",
    "          criterion = nn.CrossEntropyLoss(),\n",
    "          train_loader = train_iterator,\n",
    "          valid_loader = valid_iterator,\n",
    "          num_epochs = 8,\n",
    "          eval_every = len(train_iterator) // 2,\n",
    "          file_path = \".\",\n",
    "          best_valid_loss = float(\"Inf\")):\n",
    "    \n",
    "    # initialize running values\n",
    "    running_loss = 0.0\n",
    "    valid_running_loss = 0.0\n",
    "    global_step = 0\n",
    "    train_loss_list = []\n",
    "    valid_loss_list = []\n",
    "    global_steps_list = []\n",
    "\n",
    "    # training loop\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "\n",
    "        batch_counter = 0\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            batch_counter += 1\n",
    "            print(\"\\r%d / %d\" % (batch_counter, len(train_loader)), end=\"\")\n",
    "            output = model(batch.Question, batch.Target)\n",
    "            loss, _ = output\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # update running values\n",
    "            running_loss += loss.item()\n",
    "            global_step += 1\n",
    "\n",
    "            # evaluation step\n",
    "            if global_step % eval_every == 0:\n",
    "                model.eval()\n",
    "                with torch.no_grad():                    \n",
    "\n",
    "                    # validation loop\n",
    "                    for valid_batch in valid_loader:\n",
    "                        output = model(valid_batch.Question, valid_batch.Target)\n",
    "                        loss, _ = output\n",
    "                        \n",
    "                        valid_running_loss += loss.item()\n",
    "\n",
    "                # evaluation\n",
    "                average_train_loss = running_loss / eval_every\n",
    "                average_valid_loss = valid_running_loss / len(valid_loader)\n",
    "                train_loss_list.append(average_train_loss)\n",
    "                valid_loss_list.append(average_valid_loss)\n",
    "                global_steps_list.append(global_step)\n",
    "\n",
    "                # resetting running values\n",
    "                running_loss = 0.0                \n",
    "                valid_running_loss = 0.0\n",
    "                model.train()\n",
    "\n",
    "                # print progress\n",
    "                print('\\nEpoch [{}/{}], Step [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}'\n",
    "                      .format(epoch+1, num_epochs, global_step, num_epochs*len(train_loader),\n",
    "                              average_train_loss, average_valid_loss))\n",
    "                \n",
    "                # checkpoint\n",
    "                if best_valid_loss > average_valid_loss:\n",
    "                    best_valid_loss = average_valid_loss\n",
    "                    save_checkpoint(file_path + '/' + 'model.pt', model, best_valid_loss)\n",
    "                    save_metrics(file_path + '/' + 'metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n",
    "    \n",
    "        end_time = time.time()\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    save_metrics(file_path + '/' + 'metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n",
    "    print('\\nFinished Training!')\n",
    "\n",
    "model = BERT(bert).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=2e-5)\n",
    "\n",
    "train(model=model, optimizer=optimizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
