{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_files(path):\n",
    "    return glob.glob(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(filename):\n",
    "    with open(filename) as json_file:\n",
    "        data = json.load(json_file)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adat beolvasása JSON fájlból"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file: Data/gyakori_szamitastechnika\n",
      "Reading file: Data/gyakori_egeszseg_20000\n",
      "Reading file: Data/gyakori_szorakozas_30000\n",
      "Reading file: Data/gyakori_egeszseg\n",
      "Reading file: Data/gyakori_allatok_14000\n"
     ]
    }
   ],
   "source": [
    "json_data = []\n",
    "\n",
    "for file in find_files('Data/*'):\n",
    "    print(\"Reading file:\", file)\n",
    "    json_data.append(read_json(file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe-mé alakítás"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_frames = []\n",
    "\n",
    "for data in json_data:\n",
    "    data_frames.append(pd.DataFrame(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bepillantás a kérdésekbe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valasz</th>\n",
       "      <th>kategoriak</th>\n",
       "      <th>hosszu_kerdes</th>\n",
       "      <th>rovid_kerdes</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Várak régen is voltak. Ha mindhárom tornyot le...</td>\n",
       "      <td>[Számítástechnika, Internet]</td>\n",
       "      <td>Miért lett ilyen sz@r a honfoglaló? Régen tök ...</td>\n",
       "      <td>Miért lett ilyen sz@r a honfoglaló?</td>\n",
       "      <td>[Honfoglaló, vár]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ahogy írták, az stdio az a C-s függvénykönyvtá...</td>\n",
       "      <td>[Számítástechnika, Programozás]</td>\n",
       "      <td>C++-ban melyiket érdemesebb használni? Stdio v...</td>\n",
       "      <td>C++-ban melyiket érdemesebb használni? Stdio v...</td>\n",
       "      <td>[C++, iostream, konzol, Windows, Visual Studio]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              valasz  \\\n",
       "0  Várak régen is voltak. Ha mindhárom tornyot le...   \n",
       "1  Ahogy írták, az stdio az a C-s függvénykönyvtá...   \n",
       "\n",
       "                        kategoriak  \\\n",
       "0     [Számítástechnika, Internet]   \n",
       "1  [Számítástechnika, Programozás]   \n",
       "\n",
       "                                       hosszu_kerdes  \\\n",
       "0  Miért lett ilyen sz@r a honfoglaló? Régen tök ...   \n",
       "1  C++-ban melyiket érdemesebb használni? Stdio v...   \n",
       "\n",
       "                                        rovid_kerdes  \\\n",
       "0                Miért lett ilyen sz@r a honfoglaló?   \n",
       "1  C++-ban melyiket érdemesebb használni? Stdio v...   \n",
       "\n",
       "                                          keywords  \n",
       "0                                [Honfoglaló, vár]  \n",
       "1  [C++, iostream, konzol, Windows, Visual Studio]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frames[0].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kérdések megszámolása, átlagos hossz számolása"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_avg(data_frames, label=\"rovid_kerdes\"):\n",
    "    avg = 0\n",
    "    count = 0\n",
    "    \n",
    "    for frame in data_frames:\n",
    "        for index, row in frame.iterrows():\n",
    "            avg += len(row[label])\n",
    "            count += 1\n",
    "\n",
    "    avg = avg / count\n",
    "    \n",
    "    return avg, count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extrém rövid/hosszú kérdések eldobása"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_extreme(data_frames, min_, max_, label=\"rovid_kerdes\"):\n",
    "    for idx, frame in enumerate(data_frames):\n",
    "        frame = frame[frame[label].map(len) >= min_]\n",
    "        frame = frame[frame[label].map(len) <= max_]\n",
    "\n",
    "        data_frames[idx] = frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of questions: 168127\n",
      "Average length: 346.495816\n"
     ]
    }
   ],
   "source": [
    "long_questions_avg_len, questions_count = calculate_avg(data_frames, \"hosszu_kerdes\")\n",
    "\n",
    "print(\"Number of questions: %d\" % questions_count)\n",
    "print(\"Average length: %f\" % long_questions_avg_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of questions: 137265\n",
      "Average length: 326.753950\n"
     ]
    }
   ],
   "source": [
    "drop_extreme(data_frames, long_questions_avg_len / 4, long_questions_avg_len * 3, \"hosszu_kerdes\")\n",
    "long_questions_avg_len, questions_count = calculate_avg(data_frames, \"hosszu_kerdes\")\n",
    "\n",
    "print(\"Number of questions: %d\" % questions_count)\n",
    "print(\"Average length: %f\" % long_questions_avg_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Számítástechnika', 'Egészség', 'Szórakozás', 'Állatok']\n"
     ]
    }
   ],
   "source": [
    "target_dir = {}\n",
    "target_names = []\n",
    "\n",
    "target_values = []\n",
    "long_questions = []\n",
    "\n",
    "for frame in data_frames:\n",
    "    for idx in frame.index:\n",
    "        category = frame[\"kategoriak\"][idx][0]\n",
    "        if category not in target_names:\n",
    "            target_dir[category] = len(target_dir)\n",
    "            target_names.append(category)\n",
    "        target_values.append(target_dir[category])\n",
    "        long_questions.append(frame[\"hosszu_kerdes\"][idx])\n",
    "print(target_names)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Állatok\n",
      "Hová tűnnek a garnélák petéi? Már a második garnélámmal jártam úgy, hogy kb 3-4 héttel a petésedés után egyik napról a másikra eltűntek a peték a hasáról. Már szépen látszottak a kis pontok amik a kis garnélák szemei voltak a petéken, és az elsőnél azt hittem hogy kikeltek, de egyet sem látok az akváriumon most a második nőstény pete nélkülivé válása utána is.Ez az első alkalom hogy szaporodni kezdtek nálam, és nem tudom, lehet kikeltek de olyan kicsik hogy nem látom őket? Kerestem de egyet se láttam, az a baj hogy nem tudom mit kéne keressek. Lehet hogy a halivadékok megették őket? Egy centinél kisebb ivadékok vannak csak, amint elérik az 1 cm-t kiveszem őket a nagy akváriumba. Ők csak nem ehették meg őket, nem?\n",
      "--------------------------------------\n",
      "Szórakozás\n",
      "Hogy indíthatok pert, egy MMORPG privát szerver ellen? Hol tudnék utána nézni játék jogtörvényeknek? Lehetne ezt interneten keresztül kikeresni? Elérkeztem arra a pontra, hogy egy MMORPG szerver ellen belefogjak egy perbe, ebben kérnék tanácsot, hogy aki már gondolt hasonlóra és elkezdett kutakodni talált valami kézzelfoghatót? Tehát mi a teendő akkor, ha valakit jogtalanul tiltanak ki egy játékról ahová esetlegesen pénzt is költött. Gondolom ez a játék hivatalosan bejelentett cégként futhat tehát adózik, ergo van felelőssége. Csak simán keressek fel egy ügyvédet és ő tudni fogja a következő lépéseket?\n",
      "--------------------------------------\n",
      "Szórakozás\n",
      "Mi a legbizarrabb, legfurább, legegyedibb zene, amit ismertek/szerettek? Bármilyen stílusban jöhet. Olyasmi, ami nagy hatást tett rátok zavarbaejtő, bizarr, szokatlan, esetleg nyomasztó vagy rémisztő mivolta miatt.\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "paired = list(zip(target_values, long_questions))\n",
    "\n",
    "random.shuffle(paired)\n",
    "\n",
    "target_values, long_questions = zip(*paired)\n",
    "long_questions = list(long_questions)\n",
    "\n",
    "for i in range(0, 3):\n",
    "    print(target_names[target_values[i]])\n",
    "    print(long_questions[i])\n",
    "    print(\"--------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicode_to_ascii(data):\n",
    "    return \" \".join(unidecode.unidecode(re.sub(r\"[,.;@#?!&$]+\\ *\", \" \", data).lower()).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unidecode\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "vocab = Counter()\n",
    "\n",
    "for idx, q in enumerate(long_questions):\n",
    "    words = unidecode.unidecode(re.sub(r\"[,.;@#?!&$]+\\ *\", \" \", q).lower()).split()\n",
    "    for word in words:\n",
    "        vocab[word] += 1\n",
    "    long_questions[idx] = \" \".join(words)\n",
    "\n",
    "total_words = len(vocab)\n",
    "\n",
    "word_to_index = {}\n",
    "\n",
    "for idx, word in enumerate(vocab):\n",
    "    word_to_index[word] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(text, target, i, batch_size):\n",
    "\n",
    "    batches = []\n",
    "    results = []\n",
    "    \n",
    "    texts = text[i * batch_size : i * batch_size + batch_size]\n",
    "    categories = target[i * batch_size : i * batch_size + batch_size]\n",
    "\n",
    "    for text in texts:\n",
    "        layer = np.zeros(total_words , dtype=float)\n",
    "        for word in text.split():\n",
    "            layer[word_to_index[word.lower()]] += 1\n",
    "            \n",
    "        batches.append(layer)\n",
    "        \n",
    "    for category in categories:\n",
    "        results.append(category)\n",
    "     \n",
    "    return np.array(batches), np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "num_epochs = 3\n",
    "batch_size = 150\n",
    "display_step = 1\n",
    "\n",
    "hidden_size = 100\n",
    "input_size = total_words\n",
    "num_classes = len(target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OurNet(nn.Module):\n",
    "     def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(OurNet, self).__init__()\n",
    "        self.layer_1 = nn.Linear(input_size,hidden_size, bias=True)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layer_2 = nn.Linear(hidden_size, hidden_size, bias=True)\n",
    "        self.output_layer = nn.Linear(hidden_size, num_classes, bias=True)\n",
    " \n",
    "     def forward(self, x):\n",
    "        out = self.layer_1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.layer_2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.output_layer(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "input_ = Variable(torch.randn(2, 5), requires_grad=True)\n",
    "target = Variable(torch.LongTensor(2).random_(5))\n",
    "output = loss(input_, target)\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [4/40], Loss: 1.2716\n",
      "Epoch [1/5], Step [8/40], Loss: 0.9863\n",
      "Epoch [1/5], Step [12/40], Loss: 0.7888\n",
      "Epoch [1/5], Step [16/40], Loss: 0.6884\n",
      "Epoch [1/5], Step [20/40], Loss: 0.5506\n",
      "Epoch [1/5], Step [24/40], Loss: 0.7647\n",
      "Epoch [1/5], Step [28/40], Loss: 0.5964\n",
      "Epoch [1/5], Step [32/40], Loss: 0.6129\n",
      "Epoch [1/5], Step [36/40], Loss: 0.4186\n",
      "Epoch [1/5], Step [40/40], Loss: 0.5360\n",
      "Epoch [2/5], Step [4/40], Loss: 0.0890\n",
      "Epoch [2/5], Step [8/40], Loss: 0.0830\n",
      "Epoch [2/5], Step [12/40], Loss: 0.0697\n",
      "Epoch [2/5], Step [16/40], Loss: 0.0481\n",
      "Epoch [2/5], Step [20/40], Loss: 0.0098\n",
      "Epoch [2/5], Step [24/40], Loss: 0.0510\n",
      "Epoch [2/5], Step [28/40], Loss: 0.0299\n",
      "Epoch [2/5], Step [32/40], Loss: 0.0545\n",
      "Epoch [2/5], Step [36/40], Loss: 0.0105\n",
      "Epoch [2/5], Step [40/40], Loss: 0.0209\n",
      "Epoch [3/5], Step [4/40], Loss: 0.0074\n",
      "Epoch [3/5], Step [8/40], Loss: 0.0008\n",
      "Epoch [3/5], Step [12/40], Loss: 0.0005\n",
      "Epoch [3/5], Step [16/40], Loss: 0.0005\n",
      "Epoch [3/5], Step [20/40], Loss: 0.0003\n",
      "Epoch [3/5], Step [24/40], Loss: 0.0023\n",
      "Epoch [3/5], Step [28/40], Loss: 0.0034\n",
      "Epoch [3/5], Step [32/40], Loss: 0.0020\n",
      "Epoch [3/5], Step [36/40], Loss: 0.0002\n",
      "Epoch [3/5], Step [40/40], Loss: 0.0002\n",
      "Epoch [4/5], Step [4/40], Loss: 0.0001\n",
      "Epoch [4/5], Step [8/40], Loss: 0.0001\n",
      "Epoch [4/5], Step [12/40], Loss: 0.0002\n",
      "Epoch [4/5], Step [16/40], Loss: 0.0004\n",
      "Epoch [4/5], Step [20/40], Loss: 0.0002\n",
      "Epoch [4/5], Step [24/40], Loss: 0.0001\n",
      "Epoch [4/5], Step [28/40], Loss: 0.0005\n",
      "Epoch [4/5], Step [32/40], Loss: 0.0001\n",
      "Epoch [4/5], Step [36/40], Loss: 0.0000\n",
      "Epoch [4/5], Step [40/40], Loss: 0.0000\n",
      "Epoch [5/5], Step [4/40], Loss: 0.0001\n",
      "Epoch [5/5], Step [8/40], Loss: 0.0001\n",
      "Epoch [5/5], Step [12/40], Loss: 0.0001\n",
      "Epoch [5/5], Step [16/40], Loss: 0.0002\n",
      "Epoch [5/5], Step [20/40], Loss: 0.0001\n",
      "Epoch [5/5], Step [24/40], Loss: 0.0000\n",
      "Epoch [5/5], Step [28/40], Loss: 0.0003\n",
      "Epoch [5/5], Step [32/40], Loss: 0.0001\n",
      "Epoch [5/5], Step [36/40], Loss: 0.0000\n",
      "Epoch [5/5], Step [40/40], Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "net = OurNet(input_size, hidden_size, num_classes)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)  \n",
    "\n",
    "train_text = long_questions[:6000]\n",
    "train_target = target_values[:6000]\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_batch = int(len(train_text) / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_x,batch_y = get_batch(train_text, train_target, i, batch_size)\n",
    "        articles = Variable(torch.FloatTensor(batch_x))\n",
    "        labels = Variable(torch.LongTensor(batch_y))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(articles)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i + 1) % 4 == 0:\n",
    "            print ('Epoch [%d/%d], Step [%d/%d], Loss: %.4f' %(epoch + 1, num_epochs, i + 1, len(train_text) // batch_size, loss.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mennyi kérdésed van?\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(\"Mennyi kérdésed van?\")\n",
    "q_num = int(input())\n",
    "\n",
    "for q in range(0, q_num):\n",
    "    test_text = input()\n",
    "\n",
    "    test_data = [unicode_to_ascii(test_text)]\n",
    "    total_test_data = 1\n",
    "\n",
    "    batch_x_test, batch_y_test = get_batch(test_data, [0], 0, total_test_data)\n",
    "    articles = Variable(torch.FloatTensor(batch_x_test))\n",
    "    labels = torch.LongTensor(batch_y_test)\n",
    "    outputs = net(articles)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "    print(\"A kérdés %s témájú .. talán.\" % target_names[predicted.item()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
