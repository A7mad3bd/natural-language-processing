{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be79b16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import torch.nn as nn\n",
    "\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification, AutoTokenizer, AutoModel, AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import f1_score, balanced_accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import seaborn as sn\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39b356a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time \n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from argparse import Namespace\n",
    "\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification, AdamW, \\\n",
    "    get_linear_schedule_with_warmup\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a29ed7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(\n",
    "    dataset_dir = \".data\",\n",
    "    dataset_prefix = \"faq_with_splits_\",\n",
    "    dataset = \"lemmatized_filtered\",\n",
    "    models = [\"bert-base-multilingual-uncased\"],\n",
    "    model_save_dir = \".model_storage/BERT\",\n",
    "    model_state_file = \"model\",\n",
    "    seed = 1234,\n",
    "    num_epochs = 2,\n",
    "    learning_rate = 5e-5,\n",
    "    hidden_size = 100,\n",
    "    batch_size = 16,\n",
    "    cuda = True,\n",
    "    train_column = 'short_question'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1192120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if args.cuda & torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4fbe683b",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.model_state_file = os.path.join(args.model_save_dir, args.model_state_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "87116c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".data\\faq_with_splits_lemmatized_filtered\n"
     ]
    }
   ],
   "source": [
    "args.dataset = os.path.join(args.dataset_dir, args.dataset_prefix + args.dataset)\n",
    "print(args.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f090921",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "torch.cuda.manual_seed_all(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8cc17295",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizers = {}\n",
    "\n",
    "for model in args.models:\n",
    "    tokenizers[model] = BertTokenizerFast.from_pretrained(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "20860c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(args.dataset + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4e01281c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>short_question</th>\n",
       "      <th>long_question</th>\n",
       "      <th>answer</th>\n",
       "      <th>main_category</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tudt kutya tanítás foglalkozó személy aki tud ...</td>\n",
       "      <td>tudt kutya tanítás foglalkozó személy aki tud ...</td>\n",
       "      <td>Nem kellene általánosítani egy szar kutyaiskol...</td>\n",
       "      <td>Állatok</td>\n",
       "      <td>Kutyák</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7 hetes francia bulldog kaphat rizs</td>\n",
       "      <td>7 hetes francia bulldog kaphat rizs sziaszt 7 ...</td>\n",
       "      <td>Orvost kaphat, nem rizst!</td>\n",
       "      <td>Állatok</td>\n",
       "      <td>Kutyák</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anime segitség nézik</td>\n",
       "      <td>anime segitség nézik kifogytam romantikus ross...</td>\n",
       "      <td>Nézd meg az Inuyashát.</td>\n",
       "      <td>Szórakozás</td>\n",
       "      <td>Filmek, sorozatok</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c input handler feladat megoldás</td>\n",
       "      <td>k patrick nevű felhasználó kérdés c input hand...</td>\n",
       "      <td>Visual Studio-ban például lehet.</td>\n",
       "      <td>Számítástechnika</td>\n",
       "      <td>Programozás</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>az állat tényleg érez ember kisugárzás</td>\n",
       "      <td>az állat tényleg érez ember kisugárzás én szer...</td>\n",
       "      <td>A kutyák nagyon jól olvassák az emberi testbes...</td>\n",
       "      <td>Állatok</td>\n",
       "      <td>Egyéb kérdések</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      short_question  \\\n",
       "0  tudt kutya tanítás foglalkozó személy aki tud ...   \n",
       "1                7 hetes francia bulldog kaphat rizs   \n",
       "2                               anime segitség nézik   \n",
       "3                   c input handler feladat megoldás   \n",
       "4             az állat tényleg érez ember kisugárzás   \n",
       "\n",
       "                                       long_question  \\\n",
       "0  tudt kutya tanítás foglalkozó személy aki tud ...   \n",
       "1  7 hetes francia bulldog kaphat rizs sziaszt 7 ...   \n",
       "2  anime segitség nézik kifogytam romantikus ross...   \n",
       "3  k patrick nevű felhasználó kérdés c input hand...   \n",
       "4  az állat tényleg érez ember kisugárzás én szer...   \n",
       "\n",
       "                                              answer     main_category  \\\n",
       "0  Nem kellene általánosítani egy szar kutyaiskol...           Állatok   \n",
       "1                          Orvost kaphat, nem rizst!           Állatok   \n",
       "2                             Nézd meg az Inuyashát.        Szórakozás   \n",
       "3                   Visual Studio-ban például lehet.  Számítástechnika   \n",
       "4  A kutyák nagyon jól olvassák az emberi testbes...           Állatok   \n",
       "\n",
       "        sub_category  split  \n",
       "0             Kutyák    val  \n",
       "1             Kutyák    val  \n",
       "2  Filmek, sorozatok  train  \n",
       "3        Programozás  train  \n",
       "4     Egyéb kérdések  train  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "79052258",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['main_category', args.train_column, 'split']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6eb30534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>main_category</th>\n",
       "      <th>short_question</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Állatok</td>\n",
       "      <td>tudt kutya tanítás foglalkozó személy aki tud ...</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Állatok</td>\n",
       "      <td>7 hetes francia bulldog kaphat rizs</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Szórakozás</td>\n",
       "      <td>anime segitség nézik</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Számítástechnika</td>\n",
       "      <td>c input handler feladat megoldás</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Állatok</td>\n",
       "      <td>az állat tényleg érez ember kisugárzás</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      main_category                                     short_question  split\n",
       "0           Állatok  tudt kutya tanítás foglalkozó személy aki tud ...    val\n",
       "1           Állatok                7 hetes francia bulldog kaphat rizs    val\n",
       "2        Szórakozás                               anime segitség nézik  train\n",
       "3  Számítástechnika                   c input handler feladat megoldás  train\n",
       "4           Állatok             az állat tényleg érez ember kisugárzás  train"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0f2408dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Állatok', 'Szórakozás', 'Számítástechnika', 'Egészség']\n",
      "{'Állatok': 0, 'Szórakozás': 1, 'Számítástechnika': 2, 'Egészség': 3}\n"
     ]
    }
   ],
   "source": [
    "target_names = df.main_category.unique().tolist()\n",
    "target_dict = {k: v for v, k in enumerate(target_names)}\n",
    "\n",
    "print(target_names)\n",
    "print(target_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9b78206a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.main_category = df.main_category.apply(lambda x: target_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2b6250b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d7474632",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(df, tokenizer):\n",
    "    return tokenizer.batch_encode_plus(\n",
    "        df[args.train_column].tolist(),\n",
    "        max_length = max_seq_len,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_token_type_ids=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e4fdd236",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = df[df.split == 'val']\n",
    "train_df = df[df.split == 'train']\n",
    "test_df = df[df.split == 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "88e10fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data = {}\n",
    "\n",
    "for model in args.models:\n",
    "    encoded_data[model] = {}\n",
    "    tokenizer = tokenizers[model]\n",
    "    encoded_data[model]['train'] = tokenize(train_df, tokenizer)\n",
    "    encoded_data[model]['valid'] = tokenize(valid_df, tokenizer)\n",
    "    encoded_data[model]['test'] = tokenize(test_df, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4e531a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = {}\n",
    "attention_masks = {}\n",
    "\n",
    "for model in args.models:\n",
    "    input_ids[model] = {}\n",
    "    attention_masks[model] = {}\n",
    "    \n",
    "    for split in ['train', 'valid', 'test']:\n",
    "        input_ids[model][split] = encoded_data[model][split]['input_ids']\n",
    "        attention_masks[model][split] = encoded_data[model][split]['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b553bd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {}\n",
    "\n",
    "labels['train'] = torch.tensor(train_df.main_category.values)\n",
    "labels['valid'] = torch.tensor(valid_df.main_category.values)\n",
    "labels['test'] = torch.tensor(test_df.main_category.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6292889f",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "\n",
    "for model in args.models:\n",
    "    datasets[model] = {}\n",
    "    \n",
    "    for split in ['train', 'valid', 'test']:\n",
    "        datasets[model][split] = TensorDataset(\n",
    "            torch.tensor(input_ids[model][split]),\n",
    "            torch.tensor(attention_masks[model][split]),\n",
    "            labels[split]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e3d248a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {}\n",
    "\n",
    "for model in args.models:\n",
    "    dataloaders[model] = {}\n",
    "    for split in ['train', 'valid', 'test']:\n",
    "        dataloaders[model][split] = DataLoader(\n",
    "            datasets[model][split],\n",
    "            sampler=RandomSampler(datasets[model][split]),\n",
    "            batch_size=args.batch_size\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "29adf744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "class_wts = compute_class_weight('balanced', np.unique(train_df.main_category), \\\n",
    "                                 train_df.main_category)\n",
    "\n",
    "\n",
    "print(class_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "57b0c133",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.tensor(class_wts, dtype=torch.float)\n",
    "weights = weights.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "717b56da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_data_to_model(model, optimizer, criterion, bar, train):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "       \n",
    "    total_predicted = []\n",
    "    idx = 0\n",
    "\n",
    "    for batch in bar:\n",
    "        idx += 1\n",
    "        print('Batch in bar ', idx)\n",
    "        if train:\n",
    "            optimizer.zero_grad()\n",
    "            model.zero_grad()\n",
    "\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "\n",
    "        inputs = {\n",
    "            'input_ids':      batch[0],\n",
    "            'attention_mask': batch[1],\n",
    "            'labels':         batch[2],\n",
    "        }\n",
    "        \n",
    "        outputs = model(**inputs)\n",
    "        \n",
    "        logits = outputs[1]\n",
    "        loss = criterion(logits, batch[2])\n",
    "            \n",
    "#        acc = class_accuracy(predictions, batch.main_category)\n",
    "        \n",
    "        if train:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            \n",
    "        epoch_loss += loss.item()\n",
    "#        epoch_acc += acc.item()\n",
    "\n",
    "#        _, predicted = torch.max(predictions.data, 1)\n",
    "#        total_predicted += predicted.tolist()\n",
    "        \n",
    "        bar.set_postfix(loss=(epoch_loss / idx)) #, acc=(epoch_acc / idx))\n",
    "\n",
    "    return epoch_loss / idx #, epoch_acc / len(iterator), total_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "37e409b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, criterion, bar):\n",
    "    model.train()\n",
    "    loss = show_data_to_model(model, optimizer, criterion, bar, True)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8f9bf8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, optimizer, criterion, bar):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        loss = show_data_to_model(model, optimizer, criterion, bar, False)\n",
    "            \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48523e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average='weighted')\n",
    "\n",
    "def accuracy(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return balanced_accuracy_score(y_true=labels_flat, y_pred=preds_flat)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23020e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader):\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    loss_val_total = 0\n",
    "    predictions_val, true_vals = [], []\n",
    "    \n",
    "    for batch in dataloader:\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }\n",
    "\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "        # loss = outputs[0]\n",
    "        \n",
    "        logits = outputs[1]\n",
    "        loss = cross_entropy(logits, batch[2])\n",
    "\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions_val.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "    \n",
    "    loss_val_avg = loss_val_total/len(dataloader) \n",
    "    \n",
    "    predictions_val = np.concatenate(predictions_val, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "            \n",
    "    return loss_val_avg, predictions_val, true_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc97ef9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, model_name):\n",
    "    true_vals = None\n",
    "    predictions_val = None\n",
    "    for epoch in tqdm(range(1, epochs+1)):\n",
    "    \n",
    "        model.train()\n",
    "    \n",
    "        loss_train_total = 0\n",
    "\n",
    "        progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
    "        for batch in progress_bar:\n",
    "\n",
    "            model.zero_grad()\n",
    "\n",
    "            batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "            inputs = {'input_ids':      batch[0],\n",
    "                      'attention_mask': batch[1],\n",
    "                      'labels':         batch[2],\n",
    "                     }       \n",
    "\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "            logits = outputs[1]\n",
    "            loss = cross_entropy(logits, batch[2])\n",
    "\n",
    "            loss_train_total += loss.item()\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
    "\n",
    "\n",
    "        tqdm.write(f'\\nEpoch {epoch}')\n",
    "\n",
    "        loss_train_avg = loss_train_total/len(dataloader_train)            \n",
    "        tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "\n",
    "        val_loss, predictions_val, true_vals = evaluate(dataloader_valid)\n",
    "        val_f1 = f1_score_func(predictions_val, true_vals)\n",
    "        val_bacc = accuracy(predictions_val, true_vals)\n",
    "        tqdm.write(f'Validation loss: {val_loss}')\n",
    "        tqdm.write(f'F1 Score (Weighted): {val_f1}')\n",
    "        tqdm.write(f'Balanced Accuracy Score: {val_bacc}')\n",
    "\n",
    "    torch.save(model.state_dict(), model_name)\n",
    "    return true_vals, predictions_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8bd882bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import logging\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fe93b5de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert-base-multilingual-uncased\n",
      "38\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d30a9512d0244a1912cb5bdabba7115",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "'bert-base-multilingual-uncased' epoch:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "'bert-base-multilingual-uncased' train:   0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "'bert-base-multilingual-uncased' valid:   0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Batch in bar  1\n",
      "Batch in bar  2\n",
      "Batch in bar  3\n",
      "Batch in bar  4\n",
      "Batch in bar  5\n",
      "Batch in bar  6\n",
      "Batch in bar  7\n",
      "Batch in bar  8\n",
      "Batch in bar  9\n",
      "Batch in bar  10\n",
      "Batch in bar  11\n",
      "Batch in bar  12\n",
      "Batch in bar  13\n",
      "Batch in bar  14\n",
      "Batch in bar  15\n",
      "Batch in bar  16\n",
      "Batch in bar  17\n",
      "Batch in bar  18\n",
      "Batch in bar  19\n",
      "Batch in bar  20\n",
      "Batch in bar  21\n",
      "Batch in bar  22\n",
      "Batch in bar  23\n",
      "Batch in bar  24\n",
      "Batch in bar  25\n",
      "Batch in bar  26\n",
      "Batch in bar  27\n",
      "Batch in bar  28\n",
      "Batch in bar  29\n",
      "Batch in bar  30\n",
      "Batch in bar  31\n",
      "Batch in bar  32\n",
      "Batch in bar  33\n",
      "Batch in bar  34\n",
      "Batch in bar  35\n",
      "Batch in bar  36\n",
      "Batch in bar  37\n",
      "Batch in bar  38\n",
      "Batch in bar  1\n",
      "Batch in bar  2\n",
      "Batch in bar  3\n",
      "Batch in bar  4\n",
      "Batch in bar  5\n",
      "Batch in bar  6\n",
      "Batch in bar  7\n",
      "Batch in bar  8\n",
      "Batch in bar  9\n",
      "Batch in bar  10\n",
      "Batch in bar  11\n",
      "Batch in bar  12\n",
      "Batch in bar  13\n",
      "Batch in bar  14\n",
      "Batch in bar  15\n",
      "Batch in bar  16\n",
      "Batch in bar  17\n",
      "Batch in bar  18\n",
      "Batch in bar  19\n",
      "Batch in bar  20\n",
      "Batch in bar  21\n",
      "Batch in bar  22\n",
      "Batch in bar  23\n",
      "Batch in bar  24\n",
      "Batch in bar  25\n",
      "Batch in bar  26\n",
      "Batch in bar  27\n",
      "Batch in bar  28\n",
      "Batch in bar  29\n",
      "Batch in bar  30\n",
      "Batch in bar  31\n",
      "Batch in bar  32\n",
      "Batch in bar  33\n",
      "Batch in bar  34\n",
      "Batch in bar  35\n",
      "Batch in bar  36\n",
      "Batch in bar  37\n",
      "Batch in bar  38\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_acc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\VERSEN~1\\AppData\\Local\\Temp/ipykernel_1036/3051382026.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mtrain_losses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m         \u001b[0mtrain_accuracies\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[0mvalid_losses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_acc' is not defined"
     ]
    }
   ],
   "source": [
    "train_losses = {}\n",
    "train_accuracies = {}\n",
    "\n",
    "valid_losses = {}\n",
    "valid_accuracies = {}\n",
    "\n",
    "for model_ in args.models:\n",
    "    print(model_)\n",
    "    start_time = int(time.time() * 1000)\n",
    "    \n",
    "    best_valid_loss = float('inf')\n",
    "    \n",
    "    train_losses[model_] = []\n",
    "    train_accuracies[model_] = []\n",
    "\n",
    "    valid_losses[model_] = []\n",
    "    valid_accuracies[model_] = []\n",
    "    \n",
    "    train_dl = dataloaders[model_]['test']\n",
    "    valid_dl = dataloaders[model_]['valid']\n",
    "    \n",
    "    model = BertForSequenceClassification.from_pretrained(\n",
    "        model_,\n",
    "        num_labels = len(target_names),\n",
    "        output_attentions=False,\n",
    "        output_hidden_states=False   \n",
    "    )\n",
    "        \n",
    "    optimizer = AdamW(\n",
    "        model.parameters(),\n",
    "        args.learning_rate,\n",
    "        eps=1e-8\n",
    "    )\n",
    "    \n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=0,\n",
    "        num_training_steps=len(train_dl) * args.num_epochs\n",
    "    )\n",
    "    \n",
    "    criterion = CrossEntropyLoss(weight=weights)\n",
    "    \n",
    "    model = model.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "\n",
    "    print(len(train_dl))\n",
    "    \n",
    "    epoch_bar = tqdm(desc=f\"'{model_}' epoch\", total=args.num_epochs, position=0, leave=True)\n",
    "    train_bar = tqdm(train_dl, desc=f\"'{model_}' train\", leave=False)\n",
    "    valid_bar = tqdm(valid_dl, desc=f\"'{model_}' valid\", leave=False)\n",
    "    \n",
    "    for epoch in range(args.num_epochs):\n",
    "        print(epoch)\n",
    "        train_bar.n = 0\n",
    "        valid_bar.n = 0\n",
    "        \n",
    "        train_bar.refresh()\n",
    "        valid_bar.refresh()\n",
    "\n",
    "        train_loss = train_model(model, optimizer, criterion, train_bar)\n",
    "        valid_loss = evaluate_model(model, optimizer, criterion, valid_bar)\n",
    "\n",
    "        train_losses[model_].append(train_loss)\n",
    "        train_accuracies[model_].append(train_acc)\n",
    "\n",
    "        valid_losses[model_].append(valid_loss)\n",
    "        valid_accuracies[model_].append(valid_acc)\n",
    "    \n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(model.state_dict(), args.model_state_file + \"_\" + dataset_key + \".pth\")\n",
    " \n",
    "        epoch_bar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bab8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "truth, pred = train(model, 'finetuned_BERT.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175a8e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, predictions, truth = evaluate(dataloader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6247f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(truth, predictions.argmax(1))\n",
    "cm_df = pd.DataFrame(cm, index=target_names, columns=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e4b408",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap = sn.heatmap(cm_df, annot=True, cmap='Reds', fmt='g', annot_kws={\"size\": 15}, cbar=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92be75d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_report = classification_report(truth, predictions.argmax(1), target_names=target_names)\n",
    "print(class_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
