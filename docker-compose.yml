version: '2.3'

services:
  nlp:
    build: .
    volumes:
      - ./:/nlp
      - /tmp/.X11-unix:/tmp/.X11-unix
      - /usr/local/cuda:/usr/local/cuda
    network_mode: host
    pid: host
    ports:
      - 8888:8888
    runtime: nvidia
    devices:
      - "/dev/nvidia0:/dev/nvidia0"
      - "/dev/nvidiactl:/dev/nvidiactl"
      - "/dev/nvidia-uvm:/dev/nvidia-uvm"